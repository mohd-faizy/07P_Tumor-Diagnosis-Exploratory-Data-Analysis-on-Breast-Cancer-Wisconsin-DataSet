{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Tumor Diagnosis_KNNs_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCwCWXIL8x8zNeVc7j1JCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohd-faizy/07P_Exploratory_Data_Analysis_With_Seaborn/blob/master/02_Tumor_Diagnosis_KNNs_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPgWl8-Anvz1",
        "colab_type": "text"
      },
      "source": [
        "# __Tumor Diagnosis: Part-2 Machine Learning & Data Preprocessing Using KNN Algorithm__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vveaxlODuqf",
        "colab_type": "text"
      },
      "source": [
        "## __Task 1: Loading Libraries and Data__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y34Beko2D52O",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8ac58aa1-9821-4a0c-824c-9a95c6807092"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a2086735-290a-4950-8ae2-c343ddcc9c5b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a2086735-290a-4950-8ae2-c343ddcc9c5b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving breast_cancer_data_A.csv to breast_cancer_data_A.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZnsSfPiDuqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "56054628-833a-4f1d-c9eb-c09861a4ae2a"
      },
      "source": [
        "import matplotlib.pyplot as plt     # For general visualizations\n",
        "import seaborn as sns               # Much better visualizations\n",
        "import numpy as np                  # For mathematical operations\n",
        "import pandas as pd                 # For working with .csv file\n",
        "import time                         # Python time library\n",
        "\n",
        "#keep every visualization inside the browser window\n",
        "%matplotlib inline "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTJSS9lDDuqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing data \n",
        "dataset = pd.read_csv('/content/breast_cancer_data_A.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez0zQfnl69Lo",
        "colab_type": "text"
      },
      "source": [
        "## __Task 2: Data Preprocessing &  Normalization__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvyr1JpBoyJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a8ae26dd-e216-41ce-c3ca-8f60e61ab351"
      },
      "source": [
        "# Setting diagnosis column as our target varible\n",
        "y_target = dataset.diagnosis\n",
        "\n",
        "# Counting the 'B' & 'M'\n",
        "y_target.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErL91rpgTyJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changing the target values from string to binary numbers\n",
        "\n",
        "'''\n",
        "when the target values == 'M' --True --  its change target value to binary 0\n",
        "& when the target value is false i.e. 'B' it changes it to binary 1\n",
        "'''\n",
        "y_target = np.where(y_target.values == 'M', 0, 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AHgCOGyON4m",
        "colab_type": "text"
      },
      "source": [
        "> __Mapping the values in the pandas datafram__\n",
        "\n",
        "```\n",
        "dataset['diagnosis'] = dataset['diagnosis'].map({'M': 0,'B': 1})\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eqFVAUCT4Yx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "692cea62-e8f5-4efb-80bb-dd9fdaebd04f"
      },
      "source": [
        "dataset.head(-10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.990</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.300100</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.053730</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.71190</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.570</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.086900</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.24160</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.197400</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.038320</td>\n",
              "      <td>0.020580</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.420</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.056610</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.68690</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.290</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.198000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.056880</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.40000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>924632</td>\n",
              "      <td>B</td>\n",
              "      <td>12.880</td>\n",
              "      <td>28.92</td>\n",
              "      <td>82.50</td>\n",
              "      <td>514.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.05824</td>\n",
              "      <td>0.061950</td>\n",
              "      <td>0.02343</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>0.05708</td>\n",
              "      <td>0.2116</td>\n",
              "      <td>1.3600</td>\n",
              "      <td>1.502</td>\n",
              "      <td>16.83</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.02153</td>\n",
              "      <td>0.038980</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>0.01695</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>13.89</td>\n",
              "      <td>35.74</td>\n",
              "      <td>88.84</td>\n",
              "      <td>595.7</td>\n",
              "      <td>0.1227</td>\n",
              "      <td>0.16200</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.06493</td>\n",
              "      <td>0.2372</td>\n",
              "      <td>0.07242</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>924934</td>\n",
              "      <td>B</td>\n",
              "      <td>10.290</td>\n",
              "      <td>27.61</td>\n",
              "      <td>65.67</td>\n",
              "      <td>321.4</td>\n",
              "      <td>0.09030</td>\n",
              "      <td>0.07658</td>\n",
              "      <td>0.059990</td>\n",
              "      <td>0.02738</td>\n",
              "      <td>0.1593</td>\n",
              "      <td>0.06127</td>\n",
              "      <td>0.2199</td>\n",
              "      <td>2.2390</td>\n",
              "      <td>1.437</td>\n",
              "      <td>14.46</td>\n",
              "      <td>0.012050</td>\n",
              "      <td>0.02736</td>\n",
              "      <td>0.048040</td>\n",
              "      <td>0.017210</td>\n",
              "      <td>0.01843</td>\n",
              "      <td>0.004938</td>\n",
              "      <td>10.84</td>\n",
              "      <td>34.91</td>\n",
              "      <td>69.57</td>\n",
              "      <td>357.6</td>\n",
              "      <td>0.1384</td>\n",
              "      <td>0.17100</td>\n",
              "      <td>0.20000</td>\n",
              "      <td>0.09127</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>0.08283</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>924964</td>\n",
              "      <td>B</td>\n",
              "      <td>10.160</td>\n",
              "      <td>19.59</td>\n",
              "      <td>64.73</td>\n",
              "      <td>311.7</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.07504</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.01116</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.06331</td>\n",
              "      <td>0.2441</td>\n",
              "      <td>2.0900</td>\n",
              "      <td>1.648</td>\n",
              "      <td>16.80</td>\n",
              "      <td>0.012910</td>\n",
              "      <td>0.02222</td>\n",
              "      <td>0.004174</td>\n",
              "      <td>0.007082</td>\n",
              "      <td>0.02572</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>10.65</td>\n",
              "      <td>22.88</td>\n",
              "      <td>67.88</td>\n",
              "      <td>347.3</td>\n",
              "      <td>0.1265</td>\n",
              "      <td>0.12000</td>\n",
              "      <td>0.01005</td>\n",
              "      <td>0.02232</td>\n",
              "      <td>0.2262</td>\n",
              "      <td>0.06742</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>925236</td>\n",
              "      <td>B</td>\n",
              "      <td>9.423</td>\n",
              "      <td>27.88</td>\n",
              "      <td>59.26</td>\n",
              "      <td>271.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.04971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1742</td>\n",
              "      <td>0.06059</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>2.9270</td>\n",
              "      <td>3.618</td>\n",
              "      <td>29.11</td>\n",
              "      <td>0.011590</td>\n",
              "      <td>0.01124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.03004</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>10.49</td>\n",
              "      <td>34.24</td>\n",
              "      <td>66.50</td>\n",
              "      <td>330.6</td>\n",
              "      <td>0.1073</td>\n",
              "      <td>0.07158</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.2475</td>\n",
              "      <td>0.06969</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>925277</td>\n",
              "      <td>B</td>\n",
              "      <td>14.590</td>\n",
              "      <td>22.68</td>\n",
              "      <td>96.39</td>\n",
              "      <td>657.1</td>\n",
              "      <td>0.08473</td>\n",
              "      <td>0.13300</td>\n",
              "      <td>0.102900</td>\n",
              "      <td>0.03736</td>\n",
              "      <td>0.1454</td>\n",
              "      <td>0.06147</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>1.1080</td>\n",
              "      <td>2.224</td>\n",
              "      <td>19.54</td>\n",
              "      <td>0.004242</td>\n",
              "      <td>0.04639</td>\n",
              "      <td>0.065780</td>\n",
              "      <td>0.016060</td>\n",
              "      <td>0.01638</td>\n",
              "      <td>0.004406</td>\n",
              "      <td>15.48</td>\n",
              "      <td>27.27</td>\n",
              "      <td>105.90</td>\n",
              "      <td>733.5</td>\n",
              "      <td>0.1026</td>\n",
              "      <td>0.31710</td>\n",
              "      <td>0.36620</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.2258</td>\n",
              "      <td>0.08004</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>559 rows Ã— 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "554    924632         B  ...                  0.07242          NaN\n",
              "555    924934         B  ...                  0.08283          NaN\n",
              "556    924964         B  ...                  0.06742          NaN\n",
              "557    925236         B  ...                  0.06969          NaN\n",
              "558    925277         B  ...                  0.08004          NaN\n",
              "\n",
              "[559 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWHGMy3IT-Da",
        "colab_type": "text"
      },
      "source": [
        "> `id, diagnosis and unnamed: 32` are not necessary for training the data. So let's drop these column. \n",
        "\n",
        "$'diagnosis'$ is a target varible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmLkz5deT8mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27a00b97-9fcd-4d74-8d58-f5ad21f762b4"
      },
      "source": [
        "list = ['Unnamed: 32', 'id', 'diagnosis']\n",
        "data = dataset.drop(list,axis = 1)\n",
        "data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xGAhRDSYvwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "4c83ea24-f024-4e02-9f50-125df251495f"
      },
      "source": [
        "data.head(-10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.990</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.300100</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.053730</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.71190</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.570</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.086900</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.24160</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.197400</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.038320</td>\n",
              "      <td>0.020580</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.420</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.056610</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.68690</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.290</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.198000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.056880</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.40000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>12.880</td>\n",
              "      <td>28.92</td>\n",
              "      <td>82.50</td>\n",
              "      <td>514.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.05824</td>\n",
              "      <td>0.061950</td>\n",
              "      <td>0.02343</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>0.05708</td>\n",
              "      <td>0.2116</td>\n",
              "      <td>1.3600</td>\n",
              "      <td>1.502</td>\n",
              "      <td>16.83</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.02153</td>\n",
              "      <td>0.038980</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>0.01695</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>13.89</td>\n",
              "      <td>35.74</td>\n",
              "      <td>88.84</td>\n",
              "      <td>595.7</td>\n",
              "      <td>0.1227</td>\n",
              "      <td>0.16200</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.06493</td>\n",
              "      <td>0.2372</td>\n",
              "      <td>0.07242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>10.290</td>\n",
              "      <td>27.61</td>\n",
              "      <td>65.67</td>\n",
              "      <td>321.4</td>\n",
              "      <td>0.09030</td>\n",
              "      <td>0.07658</td>\n",
              "      <td>0.059990</td>\n",
              "      <td>0.02738</td>\n",
              "      <td>0.1593</td>\n",
              "      <td>0.06127</td>\n",
              "      <td>0.2199</td>\n",
              "      <td>2.2390</td>\n",
              "      <td>1.437</td>\n",
              "      <td>14.46</td>\n",
              "      <td>0.012050</td>\n",
              "      <td>0.02736</td>\n",
              "      <td>0.048040</td>\n",
              "      <td>0.017210</td>\n",
              "      <td>0.01843</td>\n",
              "      <td>0.004938</td>\n",
              "      <td>10.84</td>\n",
              "      <td>34.91</td>\n",
              "      <td>69.57</td>\n",
              "      <td>357.6</td>\n",
              "      <td>0.1384</td>\n",
              "      <td>0.17100</td>\n",
              "      <td>0.20000</td>\n",
              "      <td>0.09127</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>0.08283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>10.160</td>\n",
              "      <td>19.59</td>\n",
              "      <td>64.73</td>\n",
              "      <td>311.7</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.07504</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.01116</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.06331</td>\n",
              "      <td>0.2441</td>\n",
              "      <td>2.0900</td>\n",
              "      <td>1.648</td>\n",
              "      <td>16.80</td>\n",
              "      <td>0.012910</td>\n",
              "      <td>0.02222</td>\n",
              "      <td>0.004174</td>\n",
              "      <td>0.007082</td>\n",
              "      <td>0.02572</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>10.65</td>\n",
              "      <td>22.88</td>\n",
              "      <td>67.88</td>\n",
              "      <td>347.3</td>\n",
              "      <td>0.1265</td>\n",
              "      <td>0.12000</td>\n",
              "      <td>0.01005</td>\n",
              "      <td>0.02232</td>\n",
              "      <td>0.2262</td>\n",
              "      <td>0.06742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>9.423</td>\n",
              "      <td>27.88</td>\n",
              "      <td>59.26</td>\n",
              "      <td>271.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.04971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1742</td>\n",
              "      <td>0.06059</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>2.9270</td>\n",
              "      <td>3.618</td>\n",
              "      <td>29.11</td>\n",
              "      <td>0.011590</td>\n",
              "      <td>0.01124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.03004</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>10.49</td>\n",
              "      <td>34.24</td>\n",
              "      <td>66.50</td>\n",
              "      <td>330.6</td>\n",
              "      <td>0.1073</td>\n",
              "      <td>0.07158</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.2475</td>\n",
              "      <td>0.06969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>14.590</td>\n",
              "      <td>22.68</td>\n",
              "      <td>96.39</td>\n",
              "      <td>657.1</td>\n",
              "      <td>0.08473</td>\n",
              "      <td>0.13300</td>\n",
              "      <td>0.102900</td>\n",
              "      <td>0.03736</td>\n",
              "      <td>0.1454</td>\n",
              "      <td>0.06147</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>1.1080</td>\n",
              "      <td>2.224</td>\n",
              "      <td>19.54</td>\n",
              "      <td>0.004242</td>\n",
              "      <td>0.04639</td>\n",
              "      <td>0.065780</td>\n",
              "      <td>0.016060</td>\n",
              "      <td>0.01638</td>\n",
              "      <td>0.004406</td>\n",
              "      <td>15.48</td>\n",
              "      <td>27.27</td>\n",
              "      <td>105.90</td>\n",
              "      <td>733.5</td>\n",
              "      <td>0.1026</td>\n",
              "      <td>0.31710</td>\n",
              "      <td>0.36620</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.2258</td>\n",
              "      <td>0.08004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>559 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0         17.990         10.38  ...          0.4601                  0.11890\n",
              "1         20.570         17.77  ...          0.2750                  0.08902\n",
              "2         19.690         21.25  ...          0.3613                  0.08758\n",
              "3         11.420         20.38  ...          0.6638                  0.17300\n",
              "4         20.290         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "554       12.880         28.92  ...          0.2372                  0.07242\n",
              "555       10.290         27.61  ...          0.2226                  0.08283\n",
              "556       10.160         19.59  ...          0.2262                  0.06742\n",
              "557        9.423         27.88  ...          0.2475                  0.06969\n",
              "558       14.590         22.68  ...          0.2258                  0.08004\n",
              "\n",
              "[559 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts7KZKv_6shi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "887unejnBX-8",
        "colab_type": "text"
      },
      "source": [
        "[__Difference between Standard scaler and MinMaxScaler?__](https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY7d1kbT8spg",
        "colab_type": "text"
      },
      "source": [
        "__Minmax scaler formula__\n",
        "\n",
        "> MinMaxScaler rescales the data set such that all feature values are in the range [0, 1] \n",
        "\n",
        "$X_{new} = \\frac{X_i - min(X)}{max(X) - min(X)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BU6AJpb72G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()  # Data normalization"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q31rGkt732Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "fb547249-fca3-4e37-f24a-3c2c703613a5"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Y21MS1CP9u",
        "colab_type": "text"
      },
      "source": [
        "> $Not-Normalized$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuXKf-Nb8dxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "39168d1c-5d83-4a62-beb8-f395655c5628"
      },
      "source": [
        "# fit is to train any model in sklearn library\n",
        "# and transform is to scale the data\n",
        "data = scaler.fit_transform(data) \n",
        "data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
              "        0.41886396],\n",
              "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
              "        0.22287813],\n",
              "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
              "        0.21343303],\n",
              "       ...,\n",
              "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
              "        0.1519087 ],\n",
              "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
              "        0.45231536],\n",
              "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
              "        0.10068215]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkUrmpxLCjwN",
        "colab_type": "text"
      },
      "source": [
        "> __Normalized__: as the gap between data is much smaller now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEi6HFUTEoYU",
        "colab_type": "text"
      },
      "source": [
        "## __Task 3: Spliting the data into test and traning dataset__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijo9bukQOzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6a_mr4OQTKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, y_target, test_size = 0.3)\n",
        "# X is features, target is y\n",
        "# test_set = 30% of our data set size"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGh_dRPcQw53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "45e3d9b9-7100-4521-b71d-3a384c628aa6"
      },
      "source": [
        "print(data.shape)\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n",
            "(171, 30)\n",
            "(398, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCingbPYbhoF",
        "colab_type": "text"
      },
      "source": [
        "## __Task 4: K-Nearest Neighbors Algorithm(KNNs)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORlEw6Vgb-oJ",
        "colab_type": "text"
      },
      "source": [
        "> - [__Introduction to k-Nearest Neighbors --> analyticsvidhya.com__](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)\n",
        "- [__KNN Algorithm - Finding Nearest Neighbors --> tutorialspoint.com__](https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_knn_algorithm_finding_nearest_neighbors.htm) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VDkqGIhd-O2",
        "colab_type": "text"
      },
      "source": [
        "### __KNN__\n",
        "- __Supervised ML algorithm__\n",
        "- Can be used for both __Classification__ as well as __Regression__.\n",
        "\n",
        "> __K-nearest neighbors (KNN)__ algorithm uses _â€˜feature similarityâ€™_ to predict the values of new datapoints which further means that the new data point will be assigned a value based on how closely it matches the points in the training set.\n",
        "\n",
        "$Steps:$\n",
        "\n",
        "- $Step-1$: Load the training as well as test data.\n",
        "- $Step-2$: Choose the value of $K$ i.e. the nearest data points. $K$ can be any integer.\n",
        "- $Step-3$:  For each point in the test data do the following:\n",
        "    - Calculate the distance between test data and each row of training data with the help of any of the method namely: Euclidean, Manhattan or Hamming distance. The most commonly used method to calculate distance is __Euclidean__.\n",
        "    - Now, based on the distance value, sort them in __Ascending order__.\n",
        "    - Next, it will choose the top $K$ rows from the sorted array.\n",
        "    - Now, it will assign a class to the test point based on most frequent class of these rows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1anFiSX9ox61",
        "colab_type": "text"
      },
      "source": [
        "__Eucledian distance__\n",
        "![__Eucledian distance__](https://upload.wikimedia.org/wikipedia/commons/1/10/Euclidean_distance_3d_2_cropped.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4XvQlciv7U",
        "colab_type": "text"
      },
      "source": [
        "__Example__\n",
        "\n",
        "Suppose we have a dataset which can be plotted as follows âˆ’\n",
        "\n",
        "\n",
        "\n",
        "![KNN1](https://www.tutorialspoint.com/machine_learning_with_python/images/concept_of_k.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvqiKP-UmVvp",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to classify new data point with black dot (at point 60,60) into blue or red class. We are assuming K = 3 i.e. it would find three nearest data points. It is shown in the next diagram âˆ’\n",
        "\n",
        "![KNN-2](https://www.tutorialspoint.com/machine_learning_with_python/images/knn_algorithm.jpg)\n",
        "\n",
        "We can see in the above diagram the three nearest neighbors of the data point with black dot. Among those three, two of them lies in Red class hence the black dot will also be assigned in red class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7JhKzCbm7Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the KNN from the Sklearn library\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZAG-TsQmVNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4STwowCPkkL9",
        "colab_type": "text"
      },
      "source": [
        "### __Grid Search & hyperparameter__\n",
        "\n",
        "This technique is used to find the _Optimal parameters_ to use with an algorithm. This is NOT the weights or the model, those are learned using the data.\n",
        "\n",
        "__Hyper-parameters__ are like the $k$ in __k-Nearest Neighbors (KNNs)__. $KNNs$ requires the user to select which neighbor to consider when calculating the distance. The algorithm then tunes a parameter, a threshold, to see if a novel example falls within the learned distribution, this is done with the data.\n",
        "\n",
        "> __This method will be able to best determine which k is the optimal to use for your data.__\n",
        "\n",
        "__How does it work?__\n",
        "\n",
        "First we build a grid. This is essentially a set of possible values that hyper-parameter can take. For our case we can use `[3, 5, 7, 11, 15]`. Then you will train your $KNN$ model for _each value_ in the grid. \n",
        "\n",
        "First we would do 3-NN, then 5-NN, and so on. For each iteration we will get a performance score which will tell you how well your algorithm performed using that value for the hyper-parameter. After we have gone through the entire grid we will select the value that gave the best performance.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLc4_QtDnsjb",
        "colab_type": "text"
      },
      "source": [
        "[Nearest Neighbor AlgorithmsÂ¶](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/neighbors.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Au5v8gZ5rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating parameter grid\n",
        "param_grid = {'n_neighbors': [5, 7, 11, 15],\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "              'leaf_size': [10, 30, 50, 100]}\n",
        "\n",
        "grid_search = GridSearchCV(knn, param_grid = param_grid)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymcE-rK9qww1",
        "colab_type": "text"
      },
      "source": [
        "$Syntax$\n",
        "\n",
        "```\n",
        "KNeighborsClassifier(n_neighbors=5,\n",
        "                     weights=â€™uniformâ€™,\n",
        "                     algorithm=â€™autoâ€™,\n",
        "                     leaf_size=30,\n",
        "                     metric=â€™minkowskiâ€™,\n",
        "                     p=2,\n",
        "                     metric_params=None)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb-ubj6Oqlq6",
        "colab_type": "text"
      },
      "source": [
        "- `n_neighbors` are the number of neighbors that will vote for the class of the target point; default number is 5. An odd number is preferred to avoid any tie.\n",
        "\n",
        "\n",
        "- `weights` parameter has two choices: `uniform` and `distance`. For the `uniform` weight, each of the __k-neighbors__ has equal vote whatever its distance from the target point. If the weight is â€˜distanceâ€˜ then voting weightage or importance varies by inverse of distance; those points who are nearest to the target point have greater influence than those who are farther away.\n",
        "\n",
        "- Parameter `algorithm` is for selecting the indexing data structure that will be used for speeding up neighborhood search; value of `auto` leaves it to algorithm to make the best choice among the three.the three algorithms, `brute`, `kd_tree`and `ball_tree`.\n",
        "\n",
        "> [__A working example of K-d tree formation and K-Nearest Neighbor algorithms__](https://ashokharnal.wordpress.com/2015/01/20/a-working-example-of-k-d-tree-formation-and-k-nearest-neighbor-algorithms/)\n",
        "\n",
        "- `leaf_size`:  Parameter â€˜leaf_sizeâ€˜ is the size of leaf in `kd_tree` or `ball_tree`. __Larger the size, greater the speed of initial indexing structure formation__ but at the cost of __delay in classification of target point__.\n",
        "\n",
        "\n",
        "- Parameter `metric` decides how distances are calculated in space. One familiar way is __euclidean distance__ but then in some cases other measures of distances such as __Manhattan distance__ are also used. A general formulation of distance metric is `minkowski` distance. When parameter $p$ is 2, it is the same as __Euclidean distance__ and when parameter $p$ is 1, it is __Manhattan distance__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg_YZLx7pmWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "4ecbfca8-14b0-4164-a1aa-c16f793620a3"
      },
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                            metric='minkowski',\n",
              "                                            metric_params=None, n_jobs=None,\n",
              "                                            n_neighbors=5, p=2,\n",
              "                                            weights='uniform'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
              "                         'leaf_size': [10, 30, 50, 100],\n",
              "                         'n_neighbors': [5, 7, 11, 15]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxhuUS394GeV",
        "colab_type": "text"
      },
      "source": [
        "> __Getting the best set of parameters from grid search__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHkXB2b84D-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4e4afe55-d976-40c3-bbe2-f42af83ac4f0"
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqYbWRu04Woa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the best set of parameter from the grid search\n",
        "knn = KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
        "                     weights='uniform')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJzoymz4xgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4ff3678f-c459-4097-915d-da08732cdb89"
      },
      "source": [
        "# fitting the knn parameters\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYqpSzBXLtOb",
        "colab_type": "text"
      },
      "source": [
        "##  __Task 5: Model Evaluation__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6cASyYPLdkc",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://interviewbubble.com/wp-content/uploads/2019/03/1pOtBHai4jFd-ujaNXPilRg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DFILu8MAXEC",
        "colab_type": "text"
      },
      "source": [
        "### __Accuracy__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8almmEJ645dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeDUardxAu9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = knn.predict(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g2cbH5nAxx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f1ad90a-6973-4249-94f5-515cd60ab0a6"
      },
      "source": [
        "print(\"Accuracy: {}%\".format(accuracy_score(y_test,predict)*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 97.07602339181285%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4nP7JEcA3qp",
        "colab_type": "text"
      },
      "source": [
        "### __Confusion matrix__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GAWKT8tBEse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQTWaP3cBIHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix= confusion_matrix(y_test, predict)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkjFoxH0BJsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "88169b69-2d1a-451e-d815-f0df3ab20aa7"
      },
      "source": [
        "sns.heatmap(matrix,annot = True, fmt = \"d\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff261f3b9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARD0lEQVR4nO3de7CcdX3H8fc3OSERUJIQGiBBCcNFqRXKBIpEEYzKzRacsYhCjDbMmXqh4AVBqMX7BCsiztTagxHSqkiMIBmHm4QgdMSQIMgt2GSwSCCQILlAxJCz++0fWegBk5w9m835nX3yfmWeObvPs+fZ70Dmk+98n98+G5mJJGnwDStdgCTtqAxgSSrEAJakQgxgSSrEAJakQrq29xs8cdSxLrPQn9n37qWlS9AQ9MKG5bGt59j49CNNZ86Icftt8/ttCztgSSpku3fAkjSo6rXSFTTNAJZULbXe0hU0zQCWVCmZ9dIlNM0AllQt9c4JYC/CSaqWrDe/9SMivhcRKyPigT77xkbEzyNiaePnmMb+iIhvRcSyiLgvIg7r7/wGsKRqqdea3/p3JXD8K/adD8zPzAOA+Y3nACcABzS2buDf+zu5ASypWtrYAWfm7cAzr9h9MjC78Xg2cEqf/f+Zm/wKGB0Re23t/M6AJVVKDmAVRER0s6lbfVFPZvb082vjM3NF4/GTwPjG4wnAY31et7yxbwVbYABLqpYBXIRrhG1/gbu138+IaPnTvgawpGrZ/svQnoqIvTJzRWPEsLKx/3Fgnz6vm9jYt0XOgCVVS3svwm3OPGB64/F04Lo++z/YWA1xJLC2z6his+yAJVVLGzvgiLgKOAYYFxHLgYuAmcCciJgBPAqc2nj59cCJwDLgj8CH+zu/ASypWtr4UeTMfP8WDk3dzGsT+NhAzm8AS6qWDvoknAEsqVIyvRuaJJXhzXgkqRBHEJJUiB2wJBVS21i6gqYZwJKqxRGEJBXiCEKSCrEDlqRCDGBJKiO9CCdJhTgDlqRCHEFIUiF2wJJUiB2wJBViByxJhfS274bs25sBLKla7IAlqRBnwJJUiB2wJBViByxJhdgBS1IhroKQpEIyS1fQNANYUrU4A5akQgxgSSrEi3CSVEitVrqCphnAkqrFEYQkFWIAS1IhzoAlqYysuw5YksrooBHEsNIFSFJb1WrNb/2IiE9ExIMR8UBEXBURoyJiUkQsjIhlEXF1ROzUaqkGsKRqqdeb37YiIiYA/wRMzsw3AsOB04CLgUszc39gNTCj1VINYEnV0qYAbugCXhURXcDOwArg7cDcxvHZwCmtluoMeDuKXXdh9GfPpWu/SZDJmq9+jVe97a2MfMtRsHEjvY8/wZqvXEw+t750qSpg5MiR3Dr/J4wcuRNdXcO55prr+eKXLildVudr0814MvPxiPg68HvgeeBm4G5gTWa+eMu15cCEVt/DAN6OdjvnLDb86i5WX/h56OoiRo1kw847s+47l0Otzqs/2s2uHzydZ7/dU7pUFbBhwwbeddyprF//R7q6urhtwbXceNMC7rrr16VL62wDuAgXEd1Ad59dPZnZ0zg2BjgZmASsAX4MHN++QpsI4Ih4faOIF1P+cWBeZi5pZyFVE7vswk6Hvok1X565aUdvL/lcLxvuWvzSazY+8BCjjn1boQo1FKxf/0cARozoYsSILrKDbqU4ZA1gGVojbLfUAb0D+F1mrgKIiGuAKcDoiOhqdMET2ZSJLdnqDDgizgN+BARwV2ML4KqIOL/VN90RDN97T+pr1jD6wvPY48oedjv/08SoUS97zc7vPoENv1pYqEINBcOGDWPRXTfx+PLfMH/+HSxadE/pkjpf+1ZB/B44MiJ2jogApgIPAQuA9zZeMx24rtVS+7sINwM4PDNnZub3G9tM4Ai2cuUvIrojYnFELP7+U0+0WltHi+HDGXHggay/dh6rPtRN/ulP7Drt/S8d33X66WStxvM33VKwSpVWr9c5/IjjmLTf4UyefCh/efBBpUvqeFmvN71t9TyZC9l0se3XwP1sysse4DzgkxGxDNgdmNVqrf0FcB3YezP792oc26zM7MnMyZk5+Yzxm/v16qutXEVt1So2PrRpUvOnBb9gxEEHAvCqE49j1JQ3s+bzXylZooaQtWvX8Ytf/JJ3HXdM6VI6Xz2b3/qRmRdl5usz842ZOS0zN2TmI5l5RGbun5l/n5kbWi21vxnwOcD8iFgKPNbY91pgf+Djrb7pjqD+zGpqT61k+Gv3ofb7xxg5+TB6f/e/jPybw9n19NP4w8fOITe0/P9NFTBu3Fg2buxl7dp1jBo1iqlT38rXL/l26bI6X1XuBZGZN0bEgWwaOfS9CLcoMzvnppuFrL30W4y56EJiRBe9T6xgzVcuZo9Z3yFGjGD3b34dgBcefIi1/3pp4UpVwl57jmfWrEsZPnw4w4YFc+f+jOuvn1+6rM7XQfeCiO191fWJo47tnP8aGjT73r20dAkagl7YsDy29Rzr/+W0pjNnly/+aJvfb1u4DlhStVRlBCFJHaeDRhAGsKRK6W952VBiAEuqFjtgSSrEAJakQvxaekkqw++Ek6RSDGBJKsRVEJJUiB2wJBViAEtSGVlzBCFJZdgBS1IZLkOTpFIMYEkqpHNGwAawpGrJ3s5JYANYUrV0Tv4awJKqxYtwklSKHbAklWEHLEml2AFLUhnZW7qC5hnAkiqlg76V3gCWVDEGsCSVYQcsSYUYwJJUSNaidAlNM4AlVYodsCQVknU7YEkqopM64GGlC5CkdsqMprf+RMToiJgbEQ9HxJKIeHNEjI2In0fE0sbPMa3WagBLqpSsN7814TLgxsx8PXAIsAQ4H5ifmQcA8xvPW+IIQlKl1Nu0CiIidgOOBj4EkJkvAC9ExMnAMY2XzQZuA85r5T3sgCVVStaj6S0iuiNicZ+tu8+pJgGrgCsi4p6I+G5E7AKMz8wVjdc8CYxvtVY7YEmVMpBVEJnZA/Rs4XAXcBhwVmYujIjLeMW4ITMzIlq+/6UdsKRKyWx+68dyYHlmLmw8n8umQH4qIvYCaPxc2WqtBrCkShnICGKr58l8EngsIg5q7JoKPATMA6Y39k0Hrmu1VkcQkiqlmeVlA3AW8IOI2Al4BPgwmxrXORExA3gUOLXVkxvAkiql1sZ7QWTmvcDkzRya2o7zG8CSKqXNHfB2ZQBLqhTvBSFJhTSxumHIMIAlVYodsCQVUqt3zupaA1hSpTiCkKRC6q6CkKQyXIYmSYU4gujjtYv/Z3u/hTrQ80/cUboEVZQjCEkqxFUQklRIB00gDGBJ1eIIQpIKcRWEJBXS3JcdDw0GsKRKSeyAJamIXkcQklSGHbAkFeIMWJIKsQOWpELsgCWpkJodsCSV0UHfSGQAS6qWuh2wJJXhzXgkqRAvwklSIfVwBCFJRdRKFzAABrCkSnEVhCQV4ioISSrEVRCSVIgjCEkqxGVoklRIrYM64GGlC5CkdqoPYGtGRAyPiHsi4meN55MiYmFELIuIqyNip1ZrNYAlVUq7Axg4G1jS5/nFwKWZuT+wGpjRaq0GsKRKyWh+609ETAROAr7beB7A24G5jZfMBk5ptVYDWFKlDKQDjojuiFjcZ+t+xem+CXyG/2+YdwfWZGZv4/lyYEKrtXoRTlKlDOSjyJnZA/Rs7lhEvBtYmZl3R8Qx7ajtlQxgSZXSxnXAU4C/i4gTgVHAa4DLgNER0dXogicCj7f6Bo4gJFVKuy7CZeZnM3NiZu4LnAbcmpmnAwuA9zZeNh24rtVaDWBJlbIdVkG80nnAJyNiGZtmwrNaPZEjCEmVsj3uBZGZtwG3NR4/AhzRjvMawJIqxXtBSFIh3pBdkgqpd9ANKQ1gSZXi3dAkqZDO6X8NYEkVYwcsSYX0Ruf0wAawpErpnPg1gCVVjCMISSrEZWiSVEjnxK8BLKliHEFIUiG1DuqBDWBJlWIHLEmFpB2wJJXRSR2w34gxCCZO3Jtbbv4x9/1mAb+591bO+viM0iVpEP3zV7/B0Sedxiln/ONL+9aue5Yzz76AE983gzPPvoC165592e/cv+S3HHL0Sdy84I7BLrfj1cmmt9IM4EHQ29vLuZ/5Am865FimvOVv+chHPsQb3nBA6bI0SE458Z185xtfftm+7/7XHI6cfCjXXz2LIycfyqzvz3npWK1W49JvX8FRhx822KVWQg5gK80AHgRPPrmSe+59AIDnnlvPww8vZcLeexauSoNl8qF/xW6vefXL9i24405OPuEdAJx8wju49fY7Xzr2w7nzeOcxUxg7ZvSg1lkVvWTTW2kG8CB73esmcughb2ThXfeULkUF/WH1GvYYNxaAcbuP4Q+r1wDw1KqnmX/7L3nfe04qWV5HywH8Ka3lAI6ID2/lWHdELI6IxfX6+lbfonJ22WVn5lx9OZ/89EU8++xzpcvREBERRGz6IrOLL/sPPvGRf2DYMHujVg3CtyK3zbasgvgCcMXmDmRmD9AD0LXThPL/zAwBXV1d/Pjqy7nqqmv56U9vKF2OCtt9zGhWPf0Me4wby6qnn2Hs6N0AePDhpZx70UwAVq9dxx13LmL48OFMPfqokuV2lKHQ2TZrqwEcEfdt6RAwvv3lVNflPZew5OFlfPOyntKlaAg45i1Hct0Nt3DmtFO57oZbOPatbwbgprlXvvSaC798CW+bcoThO0BDobNtVn8d8HjgOGD1K/YH8MvtUlEFTTnqcKad8V7uu/8hFi+6GYDPfW4mN9x4a+HKNBjOvWgmi+65jzVr1jH1lDP46IxpnDntVD71ua9yzc9uYu89/4JLvnRB6TIro5ad0wFHbqXYiJgFXJGZ/72ZYz/MzA/09waOILQ5zz/h+lb9uRHj9ottPccHXveepjPnh49eu83vty222gFn5hY/MdBM+ErSYKvMDFiSOk2VZsCS1FGGwkeMm2UAS6oURxCSVEgnrYIwgCVViiMISSrEi3CSVEgnzYC944ekSmnXDdkjYp+IWBARD0XEgxFxdmP/2Ij4eUQsbfwc02qtBrCkSsnMprd+9AKfysyDgSOBj0XEwcD5wPzMPACY33jeEgNYUqXUyKa3rcnMFZn568bjZ4ElwATgZGB242WzgVNardUAllQpAxlB9L13eWPr3tw5I2Jf4K+BhcD4zFzROPQk23BnSC/CSaqUJkYLfV/70r3LtyQidgV+ApyTmetevHl+4/czIlq+6mcAS6qUdq4DjogRbArfH2TmNY3dT0XEXpm5IiL2Ala2en5HEJIqpV3fCRebWt1ZwJLM/EafQ/OA6Y3H04HrWq3VDlhSpbTxo8hTgGnA/RFxb2PfBcBMYE5EzAAeBU5t9Q0MYEmV0q4RROOLKLZ0w/ap7XgPA1hSpXgvCEkqZCCrIEozgCVVih2wJBXSSTfjMYAlVUotO+eGlAawpEpxBixJhTgDlqRCnAFLUiF1RxCSVIYdsCQV4ioISSrEEYQkFeIIQpIKsQOWpELsgCWpkFrWSpfQNANYUqX4UWRJKsSPIktSIXbAklSIqyAkqRBXQUhSIX4UWZIKcQYsSYU4A5akQuyAJakQ1wFLUiF2wJJUiKsgJKkQL8JJUiGOICSpED8JJ0mF2AFLUiGdNAOOTvrXotNFRHdm9pSuQ0OLfy92XMNKF7CD6S5dgIYk/17soAxgSSrEAJakQgzgweWcT5vj34sdlBfhJKkQO2BJKsQAlqRCDOBBEhHHR8RvI2JZRJxfuh6VFxHfi4iVEfFA6VpUhgE8CCJiOPBvwAnAwcD7I+LgslVpCLgSOL50ESrHAB4cRwDLMvORzHwB+BFwcuGaVFhm3g48U7oOlWMAD44JwGN9ni9v7JO0AzOAJakQA3hwPA7s0+f5xMY+STswA3hwLAIOiIhJEbETcBowr3BNkgozgAdBZvYCHwduApYAczLzwbJVqbSIuAq4EzgoIpZHxIzSNWlw+VFkSSrEDliSCjGAJakQA1iSCjGAJakQA1iSCjGAJakQA1iSCvk/rit6hFw9VIUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nCtkssXBV_b",
        "colab_type": "text"
      },
      "source": [
        "### __Precision score__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWs7W8F4Bc8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee8_IgInBee7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision = precision_score(y_test, predict)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFiveXDVBgA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8296cbe-c7f1-4bce-8c80-e357fb61085c"
      },
      "source": [
        "print(\"Precision: \", precision)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:  0.9719626168224299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxlOtVOFL3u",
        "colab_type": "text"
      },
      "source": [
        "### __Recall__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyvOZ1hcLMq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzM4vwDOLQDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recall = recall_score(y_test, predict)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF4vtv-BLR4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a92f553a-3481-4522-a324-bbef5b5044e3"
      },
      "source": [
        "print(\"Recall: \", recall)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall:  0.9811320754716981\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}